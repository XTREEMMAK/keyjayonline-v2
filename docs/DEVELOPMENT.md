# Development Setup

## Prerequisites

- Node.js 22+
- npm 10+
- Access to Directus instance

## Quick Start

```bash
npm install
cp .env.example .env.local
# Edit .env.local with your credentials
npm run dev
```

## Environment Files

### Overview

```
npm run dev      → .env.development → .env.local (external Directus)
npm run docker:* → .env.docker.local (local Docker Directus)
Production       → .env (auto-generated by GitHub Actions)
```

| File | Purpose | Used By |
|------|---------|---------|
| `.env.example` | Template (committed) | Reference only |
| `.env.development` | Dev config (non-secrets) | `npm run dev` |
| `.env.local` | Dev secrets | `npm run dev` |
| `.env.docker.local` | Docker dev secrets | `npm run docker:*` |

**Note:** `.env` is NOT needed locally - it's auto-generated in production by GitHub Actions.

All `.env.*` files except `.env.example` are gitignored.

### For External Directus Development (`npm run dev`)

SvelteKit connects to Directus API, **not directly to the database**. You only need the Directus URL and token.

**Required in `.env.local`** (secrets):
```bash
DIRECTUS_TOKEN=your_external_directus_token
# CONTACT_FORM_WEBHOOK_SECRET=  # Only if testing contact form
```

**Required in `.env.development`** (config):
```bash
# Directus API
DIRECTUS_URL=http://your-directus-host:8055

# App
NODE_ENV=development
BYPASS_CORS_IN_DEV=true

# Public
PUBLIC_SITE_URL=http://localhost:5173
PUBLIC_CONTACT_EMAIL=contact@keyjayonline.com
```

**Notes:**
- DB credentials (DB_HOST, DB_USER, DB_PASSWORD) are NOT needed - Directus handles database operations
- S3/CDN config is NOT needed - assets are served directly from Directus
- S3 credentials are only for Docker development with `STORAGE_LOCATIONS=s3` in `.env.docker.local`

### For Local Docker Development (`npm run docker:*`)

**Required in `.env.docker.local`:**
```bash
DB_PASSWORD=your_db_password
DIRECTUS_KEY=<random-32-char-string>
DIRECTUS_SECRET=<random-32-char-string>
DIRECTUS_ADMIN_PASSWORD=your_admin_password
DIRECTUS_TOKEN=<generated-after-first-boot>
```

## Docker Development

### First-Time Setup

1. Create `.env.docker.local` with required secrets:
   ```bash
   cp .env.example .env.docker.local
   # Edit with your values:
   DB_PASSWORD=your_password
   DIRECTUS_KEY=$(openssl rand -hex 32)
   DIRECTUS_SECRET=$(openssl rand -hex 32)
   DIRECTUS_ADMIN_PASSWORD=your_admin_password
   DIRECTUS_TOKEN=placeholder  # Update after step 4
   ```

2. Start Directus and Postgres (skip app for now):
   ```bash
   npm run docker:init
   ```

3. Wait for Directus to be healthy:
   ```bash
   npm run docker:logs
   # Look for: "Server started at http://0.0.0.0:8055"
   # Press Ctrl+C to exit logs
   ```

4. Generate API token:
   - Access Directus at `http://localhost:8055`
   - Login with your `DIRECTUS_ADMIN_EMAIL` and `DIRECTUS_ADMIN_PASSWORD`
   - Go to Settings → Access Tokens → Create Token
   - Copy the token and update `DIRECTUS_TOKEN` in `.env.docker.local`

5. Start full stack:
   ```bash
   npm run docker:up
   ```

### Commands

```bash
npm run docker:init    # First-time: start Directus + Postgres only
npm run docker:up      # Start all containers (after token is set)
npm run docker:down    # Stop containers
npm run docker:logs    # View logs
npm run docker:build   # Rebuild app image
```

**Note:** All npm docker scripts automatically use `--profile local-db` to include the Postgres container.

### Direct Docker Compose

If not using npm scripts, source env and include the profile:
```bash
source .env.docker.local && docker compose --profile local-db up -d
```

### Services

| Service | Container | Port |
|---------|-----------|------|
| SvelteKit | kjo2_app | 3000 |
| PostgreSQL | kjo2_postgres | Internal |
| Directus | kjo2_directus | 8055 |

### Storage

- **Local dev**: Uses local filesystem (default)
- **Production**: Set `STORAGE_LOCATIONS=s3` with S3 credentials

### Schema Management

**What's included in schema export:**
- Collections, fields, relations (data model)

**What's NOT included (must be manually recreated or seeded):**
- Flows (automations)
- Roles/Permissions
- Settings
- Actual data/content

**Export schema** (from a working Directus instance):
```bash
docker exec -it directus-keyjayonline_v2-docker-directus-1 npx directus schema snapshot --yes /directus/schema.yaml
docker cp directus-keyjayonline_v2-docker-directus-1:/directus/schema.yaml ./docker/directus/schema.yaml
```

**Import schema** (to a fresh Directus container):
```bash
# Copy schema file into container
docker cp ./docker/directus/schema.yaml kjo2_directus:/directus/schema.yaml

# Apply schema (creates all collections, fields, relations)
docker exec -it kjo2_directus npx directus schema apply /directus/schema.yaml --yes

# Optional: Preview changes without applying
docker exec -it kjo2_directus npx directus schema apply /directus/schema.yaml --dry-run
```

### Seed Data & Flows

#### From Local Docker Postgres

**Export Flows, settings, and seed data** (via SQL):
```bash
# Export Directus system tables (flows, operations, settings, roles, permissions)
docker exec kjo2_postgres pg_dump -U kjo_user -d kjo_v2_db \
  --data-only \
  --table=directus_flows \
  --table=directus_operations \
  --table=directus_settings \
  --table=directus_roles \
  --table=directus_permissions \
  > ./docker/directus/system-seed.sql

# Export your app's seed data (e.g., testimonials, general settings)
docker exec kjo2_postgres pg_dump -U kjo_user -d kjo_v2_db \
  --data-only \
  --table=kjov2_general \
  --table=kjov2_socials \
  --table=kjov2_testimonials \
  > ./docker/directus/content-seed.sql
```

**Import seed data** (to fresh container):
```bash
# Copy seed files into postgres container
docker cp ./docker/directus/system-seed.sql kjo2_postgres:/tmp/
docker cp ./docker/directus/content-seed.sql kjo2_postgres:/tmp/

# Apply seeds (run AFTER schema is applied)
docker exec kjo2_postgres psql -U kjo_user -d kjo_v2_db -f /tmp/system-seed.sql
docker exec kjo2_postgres psql -U kjo_user -d kjo_v2_db -f /tmp/content-seed.sql
```

#### From External/Remote Postgres

For databases hosted externally (managed databases, remote servers, etc.), use `pg_dump` directly with connection parameters instead of `docker exec`.

**Export from external database:**
```bash
# Export Directus system tables
pg_dump -h your-db-host.com -p 5432 -U your_db_user -d your_db_name \
  --data-only \
  --table=directus_flows \
  --table=directus_operations \
  --table=directus_settings \
  --table=directus_roles \
  --table=directus_permissions \
  > ./docker/directus/system-seed.sql

# Export app content/seed data
pg_dump -h your-db-host.com -p 5432 -U your_db_user -d your_db_name \
  --data-only \
  --table=kjov2_general \
  --table=kjov2_socials \
  --table=kjov2_testimonials \
  > ./docker/directus/content-seed.sql
```

**Import to external database:**
```bash
# Apply seeds (run AFTER schema is applied)
psql -h your-db-host.com -p 5432 -U your_db_user -d your_db_name -f ./docker/directus/system-seed.sql
psql -h your-db-host.com -p 5432 -U your_db_user -d your_db_name -f ./docker/directus/content-seed.sql
```

**Tips for external databases:**
- You'll be prompted for the password, or set `PGPASSWORD` env var
- For SSL connections, add `?sslmode=require` or use `--set=sslmode=require`
- Use `.pgpass` file for automation (see [PostgreSQL docs](https://www.postgresql.org/docs/current/libpq-pgpass.html))
- For managed databases (DigitalOcean, AWS RDS, etc.), check if you need to allowlist your IP

**Example with environment variables:**
```bash
export PGHOST=your-db-host.com
export PGPORT=5432
export PGUSER=your_db_user
export PGDATABASE=your_db_name
export PGPASSWORD=your_db_password  # Or use .pgpass for security

# Now pg_dump/psql will use these automatically
pg_dump --data-only --table=directus_flows > ./docker/directus/system-seed.sql
```

**Note:** Import order matters - apply schema first, then seed data.

## Audio CORS Bypass

Development includes automatic CORS bypass for CDN audio files:

- Enabled when `BYPASS_CORS_IN_DEV=true`
- Routes CDN URLs through local proxy (`/api/proxy-audio/`)
- Automatically disabled in production builds

## Troubleshooting

**Audio not playing:**
- Check `BYPASS_CORS_IN_DEV=true` in `.env.development`
- Restart dev server after config changes

**Database connection:**
```bash
pg_isready -h your-db-host -p 5432
```

**Directus connection:**
```bash
curl http://your-directus-host:8055/server/ping
```
